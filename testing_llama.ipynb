{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca8578a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/llama-env/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e389ae8-a3b2-47ee-89da-88ae02a0fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.21\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36fe25e3-a422-4a9f-9010-c037a158e9d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 25.1 from /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/pip (python 3.9)\n",
      "Collecting llama-cpp-python==0.1.78\n",
      "  Downloading llama_cpp_python-0.1.78.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "  Running command pip subprocess to install build dependencies\n",
      "  Using pip 25.1 from /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/pip (python 3.9)\n",
      "  Collecting setuptools>=42\n",
      "    Obtaining dependency information for setuptools>=42 from https://files.pythonhosted.org/packages/58/29/93c53c098d301132196c3238c312825324740851d77a8500a2462c0fd888/setuptools-80.8.0-py3-none-any.whl.metadata\n",
      "    Using cached setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Collecting scikit-build>=0.13\n",
      "    Obtaining dependency information for scikit-build>=0.13 from https://files.pythonhosted.org/packages/c3/a3/21b519f58de90d684056c52ec4e45f744cfda7483f082dcc4dd18cc74a93/scikit_build-0.18.1-py3-none-any.whl.metadata\n",
      "    Using cached scikit_build-0.18.1-py3-none-any.whl.metadata (18 kB)\n",
      "  Collecting cmake>=3.18\n",
      "    Obtaining dependency information for cmake>=3.18 from https://files.pythonhosted.org/packages/d7/1f/2e86eb03ab8a52525347dede45ef3752b4516c19cc87be8a6546cef28839/cmake-4.0.2-py3-none-macosx_10_10_universal2.whl.metadata\n",
      "    Using cached cmake-4.0.2-py3-none-macosx_10_10_universal2.whl.metadata (6.3 kB)\n",
      "  Collecting ninja\n",
      "    Obtaining dependency information for ninja from https://files.pythonhosted.org/packages/4f/b1/3a61b348936b62a386465b1937cd778fa3a5748582e26d832dbab844ff27/ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl.metadata\n",
      "    Using cached ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl.metadata (5.0 kB)\n",
      "  Collecting distro (from scikit-build>=0.13)\n",
      "    Obtaining dependency information for distro from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "    Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "  Collecting packaging (from scikit-build>=0.13)\n",
      "    Obtaining dependency information for packaging from https://files.pythonhosted.org/packages/20/12/38679034af332785aac8774540895e234f4d07f7545804097de4b666afd8/packaging-25.0-py3-none-any.whl.metadata\n",
      "    Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Collecting tomli (from scikit-build>=0.13)\n",
      "    Obtaining dependency information for tomli from https://files.pythonhosted.org/packages/6e/c2/61d3e0f47e2b74ef40a68b9e6ad5984f6241a942f7cd3bbfbdbd03861ea9/tomli-2.2.1-py3-none-any.whl.metadata\n",
      "    Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Collecting wheel>=0.32.0 (from scikit-build>=0.13)\n",
      "    Obtaining dependency information for wheel>=0.32.0 from https://files.pythonhosted.org/packages/0b/2c/87f3254fd8ffd29e4c02732eee68a83a1d3c346ae39bc6822dcbcb697f2b/wheel-0.45.1-py3-none-any.whl.metadata\n",
      "    Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
      "  Using cached scikit_build-0.18.1-py3-none-any.whl (85 kB)\n",
      "  Using cached cmake-4.0.2-py3-none-macosx_10_10_universal2.whl (48.7 MB)\n",
      "  Using cached ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl (279 kB)\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "  Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "  Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "  Installing collected packages: wheel, tomli, setuptools, packaging, ninja, distro, cmake, scikit-build\n",
      "  \u001b[?25l\n",
      "  \u001b[2K  Creating /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-build-env-0ohop9m2/overlay/bin\n",
      "\n",
      "  \u001b[2K  changing mode of /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-build-env-0ohop9m2/overlay/bin/wheel to 755\n",
      "\n",
      "  \u001b[2K  changing mode of /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-build-env-0ohop9m2/overlay/bin/distro to 755\n",
      "\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [cmake]\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [cmake]\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [cmake]\n",
      "  \u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [cmake]\n",
      "  \u001b[2K  changing mode of /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-build-env-0ohop9m2/overlay/bin/ccmake to 755\n",
      "     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [cmake]\n",
      "  \u001b[2K  changing mode of /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-build-env-0ohop9m2/overlay/bin/cmake to 755\n",
      "     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [cmake]\n",
      "  \u001b[2K  changing mode of /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-build-env-0ohop9m2/overlay/bin/cpack to 755\n",
      "     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [cmake]\n",
      "  \u001b[2K  changing mode of /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-build-env-0ohop9m2/overlay/bin/ctest to 755\n",
      "     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m6/8\u001b[0m [cmake]\n",
      "  \u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [scikit-build]\n",
      "  \u001b[?25h\n",
      "  \u001b[1A\u001b[2KSuccessfully installed cmake-4.0.2 distro-1.9.0 ninja-1.11.1.4 packaging-25.0 scikit-build-0.18.1 setuptools-80.8.0 tomli-2.2.1 wheel-0.45.1\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Running command Getting requirements to build wheel\n",
      "  running egg_info\n",
      "  writing llama_cpp_python.egg-info/PKG-INFO\n",
      "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
      "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
      "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
      "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Running command Preparing metadata (pyproject.toml)\n",
      "  running dist_info\n",
      "  creating /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-modern-metadata-4n3q_oo7/llama_cpp_python.egg-info\n",
      "  writing /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-modern-metadata-4n3q_oo7/llama_cpp_python.egg-info/PKG-INFO\n",
      "  writing dependency_links to /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-modern-metadata-4n3q_oo7/llama_cpp_python.egg-info/dependency_links.txt\n",
      "  writing requirements to /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-modern-metadata-4n3q_oo7/llama_cpp_python.egg-info/requires.txt\n",
      "  writing top-level names to /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-modern-metadata-4n3q_oo7/llama_cpp_python.egg-info/top_level.txt\n",
      "  writing manifest file '/private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-modern-metadata-4n3q_oo7/llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  reading manifest file '/private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-modern-metadata-4n3q_oo7/llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file '/private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-modern-metadata-4n3q_oo7/llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  creating '/private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-modern-metadata-4n3q_oo7/llama_cpp_python-0.1.78.dist-info'\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/d1/0f/8d2b5ebb01dc49d20ae0a282d6baff7202b7bf0df8acdd4a6abeffe98070/numpy-2.1.0rc1.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/54/a4/f8188c4f3e07f7737683588210c073478abcb542048cf4ab6fedad0b458a/numpy-2.1.0.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/59/5f/9003bb3e632f2b58f5e3a3378902dcc73c5518070736c6740fe52454e8e1/numpy-2.1.1.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/4b/d1/8a730ea07f4a37d94f9172f4ce1d81064b7a64766b460378be278952de75/numpy-2.1.2.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/25/ca/1166b75c21abd1da445b97bf1fa2f14f423c6cfb4fc7c4ef31dccf9f6a94/numpy-2.1.3.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/d1/eb/9c688381b252f711cadf3ec38b3eceb0b946ff5a161a3adc520c886fed43/numpy-2.2.0rc1.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/47/1b/1d565e0f6e156e1522ab564176b8b29d71e13d8caf003a08768df3d5cec5/numpy-2.2.0.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/f2/a5/fdbf6a7871703df6160b5cf3dd774074b086d278172285c52c2758b76305/numpy-2.2.1.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/ec/d0/c12ddfd3a02274be06ffc71f3efc6d0e457b0409c4481596881e748cb264/numpy-2.2.2.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/fb/90/8956572f5c4ae52201fdec7ba2044b2c882832dcec7d5d0922c9e9acf2de/numpy-2.2.3.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/e1/78/31103410a57bc2c2b93a3597340a8119588571f6a4539067546cb9a0bfac/numpy-2.2.4.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/dc/b2/ce4b867d8cd9c0ee84938ae1e6a6f7926ebf928c9090d036fc3c6a04f946/numpy-2.2.5.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.10'): https://files.pythonhosted.org/packages/76/21/7d2a95e4bba9dc13d043ee156a356c0a8f0c6309dff6b21b4d71a073b8a8/numpy-2.2.6.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.10)\n",
      "  Link requires a different Python (3.9.21 not in: '>=3.11'): https://files.pythonhosted.org/packages/e7/b1/50f64d9a874841804dceb5d3e26d953114f97a35e331d2571320f1c14e51/numpy-2.3.0rc1.tar.gz (from https://pypi.org/simple/numpy/) (requires-python:>=3.11)\n",
      "Collecting numpy==1.23.4\n",
      "  Obtaining dependency information for numpy==1.23.4 from https://files.pythonhosted.org/packages/85/3a/18da9e6aa629311e97ef208e183e1bacd049c87378dfdc9c299c8a6406e1/numpy-1.23.4-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading numpy-1.23.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-cpp-python==0.1.78)\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/8b/54/b1ae86c0973cc6f0210b53d508ca3641fb6d0c56823f288d108bc7ab3cc8/typing_extensions-4.13.2-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.1.78)\n",
      "  Obtaining dependency information for diskcache>=5.6.1 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Downloading numpy-1.23.4-cp39-cp39-macosx_11_0_arm64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
      "\n",
      "\n",
      "  --------------------------------------------------------------------------------\n",
      "  -- Trying 'Ninja' generator\n",
      "  --------------------------------\n",
      "  ---------------------------\n",
      "  ----------------------\n",
      "  -----------------\n",
      "  ------------\n",
      "  -------\n",
      "  --\n",
      "  \u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
      "    Compatibility with CMake < 3.10 will be removed from a future version of\n",
      "    CMake.\n",
      "\n",
      "    Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
      "    to tell CMake that the project requires at least <min> but has been updated\n",
      "    to work with policies introduced by <max> or earlier.\n",
      "\n",
      "  \u001b[0mNot searching for unused variables given on the command line.\n",
      "\n",
      "  -- The C compiler identification is AppleClang 17.0.0.17000013\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- The CXX compiler identification is AppleClang 17.0.0.17000013\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- Configuring done (0.5s)\n",
      "  -- Generating done (0.0s)\n",
      "  -- Build files have been written to: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_cmake_test_compile/build\n",
      "  --\n",
      "  -------\n",
      "  ------------\n",
      "  -----------------\n",
      "  ----------------------\n",
      "  ---------------------------\n",
      "  --------------------------------\n",
      "  -- Trying 'Ninja' generator - success\n",
      "  --------------------------------------------------------------------------------\n",
      "\n",
      "  Configuring Project\n",
      "    Working directory:\n",
      "      /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-build\n",
      "    Command:\n",
      "      /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-build-env-0ohop9m2/overlay/lib/python3.9/site-packages/cmake/data/bin/cmake /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a -G Ninja -DCMAKE_MAKE_PROGRAM:FILEPATH=ninja --no-warn-unused-cli -DCMAKE_INSTALL_PREFIX:PATH=/private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-install -DPYTHON_VERSION_STRING:STRING=3.9.21 -DSKBUILD:INTERNAL=TRUE -DCMAKE_MODULE_PATH:PATH=/private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-build-env-0ohop9m2/overlay/lib/python3.9/site-packages/skbuild/resources/cmake -DPYTHON_EXECUTABLE:PATH=/opt/anaconda3/envs/llama-env/bin/python3.9 -DPYTHON_INCLUDE_DIR:PATH=/opt/anaconda3/envs/llama-env/include/python3.9 -DPYTHON_LIBRARY:PATH=/opt/anaconda3/envs/llama-env/lib/libpython3.9.dylib -DPython_EXECUTABLE:PATH=/opt/anaconda3/envs/llama-env/bin/python3.9 -DPython_ROOT_DIR:PATH=/opt/anaconda3/envs/llama-env -DPython_FIND_REGISTRY:STRING=NEVER -DPython_INCLUDE_DIR:PATH=/opt/anaconda3/envs/llama-env/include/python3.9 -DPython3_EXECUTABLE:PATH=/opt/anaconda3/envs/llama-env/bin/python3.9 -DPython3_ROOT_DIR:PATH=/opt/anaconda3/envs/llama-env -DPython3_FIND_REGISTRY:STRING=NEVER -DPython3_INCLUDE_DIR:PATH=/opt/anaconda3/envs/llama-env/include/python3.9 -DCMAKE_MAKE_PROGRAM:FILEPATH=ninja -DLLAMA_METAL=on -DCMAKE_OSX_DEPLOYMENT_TARGET:STRING=15.0 -DCMAKE_OSX_ARCHITECTURES:STRING=arm64 -DCMAKE_BUILD_TYPE:STRING=Release -DLLAMA_METAL=on\n",
      "\n",
      "  Not searching for unused variables given on the command line.\n",
      "  -- The C compiler identification is AppleClang 17.0.0.17000013\n",
      "  -- The CXX compiler identification is AppleClang 17.0.0.17000013\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- Found Git: /usr/bin/git (found version \"2.39.5 (Apple Git-154)\")\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  \u001b[33mCMake Warning at vendor/llama.cpp/CMakeLists.txt:117 (message):\n",
      "    Git repository not found; to enable automatic generation of build info,\n",
      "    make sure Git is installed and the project is a Git repository.\n",
      "\n",
      "  \u001b[0m\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "  -- Found Threads: TRUE\n",
      "  -- Accelerate framework found\n",
      "  -- CMAKE_SYSTEM_PROCESSOR: arm64\n",
      "  -- ARM detected\n",
      "  \u001b[33mCMake Warning (dev) at vendor/llama.cpp/CMakeLists.txt:546 (install):\n",
      "    Target llama has RESOURCE files but no RESOURCE DESTINATION.\n",
      "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "  \u001b[0m\n",
      "  -- Configuring done (0.4s)\n",
      "  -- Generating done (0.0s)\n",
      "  -- Build files have been written to: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-build\n",
      "  [1/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o\n",
      "  [2/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-metal.m.o\n",
      "  [3/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/k_quants.c.o\n",
      "  [4/9] Building CXX object vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o\n",
      "  [5/9] Building C object vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o\n",
      "  /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/vendor/llama.cpp/ggml.c:10698:17: warning: 'cblas_sgemm' is deprecated: first deprecated in macOS 13.3 - An updated CBLAS interface supporting ILP64 is available.  Please compile with -DACCELERATE_NEW_LAPACK to access the new headers and -DACCELERATE_LAPACK_ILP64 for ILP64 support. [-Wdeprecated-declarations]\n",
      "   10698 |                 cblas_sgemm(CblasRowMajor, CblasNoTrans, CblasTrans,\n",
      "         |                 ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/System/Library/Frameworks/vecLib.framework/Headers/cblas.h:610:6: note: 'cblas_sgemm' has been explicitly marked deprecated here\n",
      "    610 | void cblas_sgemm(const enum CBLAS_ORDER __Order,\n",
      "        |      ^\n",
      "  1 warning generated.\n",
      "  [6/9] Linking C static library vendor/llama.cpp/libggml_static.a\n",
      "  [7/9] Linking C shared library vendor/llama.cpp/libggml_shared.dylib\n",
      "  [8/9] Linking CXX shared library vendor/llama.cpp/libllama.dylib\n",
      "  [8/9] Install the project...\n",
      "  -- Install configuration: \"Release\"\n",
      "  -- Installing: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-install/lib/libggml_shared.dylib\n",
      "  -- Installing: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-install/lib/libllama.dylib\n",
      "  -- Installing: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-install/bin/convert.py\n",
      "  -- Installing: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-install/bin/convert-lora-to-ggml.py\n",
      "  -- Installing: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-install/bin/ggml-metal.metal\n",
      "  -- Installing: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/libllama.dylib\n",
      "  -- Installing: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/_skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/ggml-metal.metal\n",
      "\n",
      "  copying llama_cpp/llama_types.py -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama_types.py\n",
      "  copying llama_cpp/__init__.py -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/__init__.py\n",
      "  copying llama_cpp/llama_cpp.py -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama_cpp.py\n",
      "  copying llama_cpp/llama.py -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama.py\n",
      "  copying llama_cpp/utils.py -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/utils.py\n",
      "  copying llama_cpp/llama_grammar.py -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama_grammar.py\n",
      "  creating directory _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server\n",
      "  copying llama_cpp/server/__init__.py -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server/__init__.py\n",
      "  copying llama_cpp/server/app.py -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server/app.py\n",
      "  copying llama_cpp/server/__main__.py -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server/__main__.py\n",
      "  copying /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-install-tjb1wsl5/llama-cpp-python_d6eec6207ab74b38b028635b2e9c1f6a/llama_cpp/py.typed -> _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/py.typed\n",
      "\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama_types.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/__init__.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/utils.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  creating _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server/__init__.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server/app.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server/__main__.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/py.typed -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/libllama.dylib -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/ggml-metal.metal -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama_types.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/__init__.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama_cpp.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/utils.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/llama_grammar.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server/__init__.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server/app.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/llama_cpp/server/__main__.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server\n",
      "  copied 9 files\n",
      "  running build_ext\n",
      "  installing to _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel\n",
      "  running install\n",
      "  running install_lib\n",
      "  creating _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel\n",
      "  creating _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/llama_types.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/ggml-metal.metal -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/__init__.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/llama_cpp.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp\n",
      "  creating _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server/__init__.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server/app.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/server/__main__.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp/server\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/libllama.dylib -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/llama.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/utils.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/llama_grammar.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/setuptools/lib.macosx-15.0-arm64-cpython-39/llama_cpp/py.typed -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp\n",
      "  copied 12 files\n",
      "  running install_data\n",
      "  creating _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp_python-0.1.78.data/data\n",
      "  creating _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/lib/libggml_shared.dylib -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/lib/libllama.dylib -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/lib\n",
      "  creating _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/bin/ggml-metal.metal -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/bin/convert.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
      "  copying _skbuild/macosx-15.0-arm64-3.9/cmake-install/bin/convert-lora-to-ggml.py -> _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp_python-0.1.78.data/data/bin\n",
      "  running install_egg_info\n",
      "  running egg_info\n",
      "  writing llama_cpp_python.egg-info/PKG-INFO\n",
      "  writing dependency_links to llama_cpp_python.egg-info/dependency_links.txt\n",
      "  writing requirements to llama_cpp_python.egg-info/requires.txt\n",
      "  writing top-level names to llama_cpp_python.egg-info/top_level.txt\n",
      "  reading manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  adding license file 'LICENSE.md'\n",
      "  writing manifest file 'llama_cpp_python.egg-info/SOURCES.txt'\n",
      "  Copying llama_cpp_python.egg-info to _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/./llama_cpp_python-0.1.78-py3.9.egg-info\n",
      "  running install_scripts\n",
      "  copied 0 files\n",
      "  creating _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel/llama_cpp_python-0.1.78.dist-info/WHEEL\n",
      "  creating '/private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-wheel-s3a24kqr/.tmp-osqfs4ik/llama_cpp_python-0.1.78-cp39-cp39-macosx_15_0_arm64.whl' and adding '_skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel' to it\n",
      "  adding 'llama_cpp/__init__.py'\n",
      "  adding 'llama_cpp/ggml-metal.metal'\n",
      "  adding 'llama_cpp/libllama.dylib'\n",
      "  adding 'llama_cpp/llama.py'\n",
      "  adding 'llama_cpp/llama_cpp.py'\n",
      "  adding 'llama_cpp/llama_grammar.py'\n",
      "  adding 'llama_cpp/llama_types.py'\n",
      "  adding 'llama_cpp/py.typed'\n",
      "  adding 'llama_cpp/utils.py'\n",
      "  adding 'llama_cpp/server/__init__.py'\n",
      "  adding 'llama_cpp/server/__main__.py'\n",
      "  adding 'llama_cpp/server/app.py'\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert-lora-to-ggml.py'\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/bin/convert.py'\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/bin/ggml-metal.metal'\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/lib/libggml_shared.dylib'\n",
      "  adding 'llama_cpp_python-0.1.78.data/data/lib/libllama.dylib'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/licenses/LICENSE.md'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/METADATA'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/WHEEL'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/top_level.txt'\n",
      "  adding 'llama_cpp_python-0.1.78.dist-info/RECORD'\n",
      "  removing _skbuild/macosx-15.0-arm64-3.9/setuptools/bdist.macosx-15.0-arm64/wheel\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.78-cp39-cp39-macosx_15_0_arm64.whl size=653450 sha256=29441dd535cd4f088427d8585a216438bc3430c122fab4353ae258e40c8a3b9f\n",
      "  Stored in directory: /private/var/folders/8j/ythr_y152qx4ycdfpz80jjf80000gn/T/pip-ephem-wheel-cache-k8m8eowz/wheels/0c/b7/c5/44bc04b1032871ad214d9e23594bbffeccff9278f98691d8b3\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\n",
      "\u001b[2K  Attempting uninstall: typing-extensions\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.13.2\n",
      "\u001b[2K    Uninstalling typing_extensions-4.13.2:\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/__pycache__/typing_extensions.cpython-39.pyc\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/typing_extensions-4.13.2.dist-info/\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/typing_extensions.py\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.13.2\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 1.23.4\n",
      "\u001b[2K    Uninstalling numpy-1.23.4:\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/bin/f2py\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/bin/f2py3\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/bin/f2py3.9\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/numpy-1.23.4.dist-info/\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/numpy/\n",
      "\u001b[2K      Successfully uninstalled numpy-1.23.4\n",
      "\u001b[2K  changing mode of /opt/anaconda3/envs/llama-env/bin/f2py to 755━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K  changing mode of /opt/anaconda3/envs/llama-env/bin/f2py3 to 755m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K  changing mode of /opt/anaconda3/envs/llama-env/bin/f2py3.9 to 755\u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: diskcache━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: diskcache 5.6.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling diskcache-5.6.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/diskcache-5.6.3.dist-info/\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/diskcache/\n",
      "\u001b[2K      Successfully uninstalled diskcache-5.6.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: llama-cpp-python━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: llama_cpp_python 0.1.78━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling llama_cpp_python-0.1.78:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/4\u001b[0m [numpy]\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/bin/__pycache__/\u001b[0m [llama-cpp-python]\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/bin/convert-lora-to-ggml.py-python]\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/bin/convert.py0m [llama-cpp-python]\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/bin/ggml-metal.metalama-cpp-python]\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/libggml_shared.dylibcpp-python]\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/libllama.dylibllama-cpp-python]\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/llama_cpp/\n",
      "\u001b[2K      Removing file or directory /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/llama_cpp_python-0.1.78.dist-info/\n",
      "\u001b[2K      Successfully uninstalled llama_cpp_python-0.1.78━━━━━━━━\u001b[0m \u001b[32m3/4\u001b[0m [llama-cpp-python]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [llama-cpp-python]ma-cpp-python]\n",
      "\u001b[1A\u001b[2KSuccessfully installed diskcache-5.6.3 llama-cpp-python-0.1.78 numpy-1.23.4 typing-extensions-4.13.2\n",
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (0.32.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from huggingface_hub) (2025.5.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from huggingface_hub) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/llama-env/lib/python3.9/site-packages (from requests->huggingface_hub) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# Install llama-cpp-python with Apple GPU (Metal) support\n",
    "!CMAKE_ARGS=\"-DLLAMA_METAL=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose\n",
    "\n",
    "# Install Hugging Face Hub\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff220c49-123c-4812-a8ef-ff88e2aef46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f97cb4fa-65f8-4de9-8947-af4e077a185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGML\"\n",
    "model_basename = \"llama-2-13b-chat.ggmlv3.q2_K.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "845697ad-dc54-441b-8d0a-21c0fb143a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b94871f-e77d-4d2b-9cb3-9f760e0e961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id = model_name_or_path, filename = model_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91164612-9674-4cca-8d6a-031b24c0778c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/atharva7/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q2_K.bin'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93129ceb-5268-43ab-8e99-91d9fa940d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcpp_llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94c8cc52-ff11-4ee2-9ee0-264be4f1e8c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/atharva7/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q2_K.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_head_kv  = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 5.0e-06\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 10 (mostly Q2_K)\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =    0.11 MB\n",
      "llama_model_load_internal: mem required  = 5253.01 MB (+  400.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  =  400.00 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: loading '/opt/anaconda3/envs/llama-env/lib/python3.9/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x109918de0\n",
      "ggml_metal_init: loaded kernel_add_row                        0x109919420\n",
      "ggml_metal_init: loaded kernel_mul                            0x1099199c0\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x10991a000\n",
      "ggml_metal_init: loaded kernel_scale                          0x10991a5d0\n",
      "ggml_metal_init: loaded kernel_silu                           0x10991ab10\n",
      "ggml_metal_init: loaded kernel_relu                           0x10991b050\n",
      "ggml_metal_init: loaded kernel_gelu                           0x10991b590\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x10991b850\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x10991bc50\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x10991bf10\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x10991c1d0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x10991c490\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x10991c750\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x10991ca10\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x10991ccd0\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x10991cf90\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x10991d250\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x10991d510\n",
      "ggml_metal_init: loaded kernel_norm                           0x10991d7d0\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x10991dd10\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x10991dfd0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x10991e290\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x10991e550\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x10991e810\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x10991ec10\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x10991eed0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x10991f390\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                 0x10991f8d0\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                0x10991fb90\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                0x10991fe50\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                0x109920110\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                0x1099203d0\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                0x109920690\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                0x109920950\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                0x109920c10\n",
      "ggml_metal_init: loaded kernel_rope                           0x109920ed0\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x109921190\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x109921450\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x109921710\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x1099219d0\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize = 10922.67 MB\n",
      "ggml_metal_init: hasUnifiedMemory             = true\n",
      "ggml_metal_init: maxTransferRate              = built-in GPU\n",
      "llama_new_context_with_model: compute buffer total size =   91.35 MB\n",
      "llama_new_context_with_model: max tensor size =   128.17 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  5253.34 MB, ( 5254.05 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'eval            ' buffer, size =     1.36 MB, ( 5255.41 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =   402.00 MB, ( 5657.41 / 10922.67)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =    90.02 MB, ( 5747.42 / 10922.67)\n"
     ]
    }
   ],
   "source": [
    "lcpp_llm = Llama(\n",
    "    model_path = model_path,\n",
    "    n_threads = 2,\n",
    "    n_batch = 512,\n",
    "    n_gpu_layers = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05fa4db3-e207-444e-b4ad-dfb380d7d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a code for linear regression\"\n",
    "\n",
    "prompt_template = f''' SYSTEM: You are a helpful assistant and your task is to help the users with their questions in the prompt. answer in as much detail as possible\n",
    "\n",
    "USER: {prompt}\n",
    "\n",
    "ASSISTANT: \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98b6147e-2d1d-46c6-ba39-0dec9e689a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   724.85 ms\n",
      "llama_print_timings:      sample time =   244.84 ms /   420 runs   (    0.58 ms per token,  1715.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =   724.77 ms /    51 tokens (   14.21 ms per token,    70.37 tokens per second)\n",
      "llama_print_timings:        eval time = 27360.71 ms /   419 runs   (   65.30 ms per token,    15.31 tokens per second)\n",
      "llama_print_timings:       total time = 28685.32 ms\n"
     ]
    }
   ],
   "source": [
    "response = lcpp_llm(prompt = prompt_template, max_tokens = 512, temperature = 0.5, top_p = 0.95,\n",
    "                    repeat_penalty = 1.2, top_k = 150, echo = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7df34981-5082-4258-a6e9-775102db9cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcpp_llm.params.n_gpu_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55c8095d-1446-4b71-ba42-fba7f10d0188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-626e8f8c-c942-4003-8520-7763c8b8246b', 'object': 'text_completion', 'created': 1748296844, 'model': '/Users/atharva7/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGML/snapshots/3140827b4dfcb6b562cd87ee3d7f07109b014dd0/llama-2-13b-chat.ggmlv3.q2_K.bin', 'choices': [{'text': ' SYSTEM: You are a helpful assistant and your task is to help the users with their questions in the prompt. answer in as much detail as possible\\n\\nUSER: Write a code for linear regression\\n\\nASSISTANT: \\nOf course! Linear regression is a common statistical model used to predict a continuous outcome variable based on one or more predictor variables. Here\\'s an example of how you could implement linear regression in Python using scikit-learn library:\\n```\\nfrom sklearn.linear_model import LinearRegression\\nimport numpy as np\\n\\n# Generate some sample data\\nX = np.random.normal(0, 1, size=(100, 5)) # X features\\ny = np.random.normal(0, 1, size=100) # y outcome variable\\n\\n# Create a Linear Regression object and fit the model\\nlr_model = LinearRegression()\\nX_train = X[:80] # train set\\ny_train = y[:80] # train labels\\nlr_model.fit(X_train, y_train)\\n\\n# Predict on test set\\nX_test = X[80:] # test set\\npreds = lr_model.predict(X_test)\\n\\n# Evaluate the model\\nprint(\"Coefficients:\", lr_model.coef_)\\nprint(\"Standard error:\", lr_model.score(X_train, y_train))\\nprint(\"R-squared value:\", lr_model.rsquared_)\\n```\\nThis code generates some sample data, creates a linear regression object and fits the model to the training data using `fit()` method. Then it uses the `predict()` method to make predictions on the test set. Finally, it evaluates the model\\'s performance by printing the coefficients, standard error and R-squared value.\\n\\nPlease note that this is just an example code and you may need to modify it according to your specific needs and data. Also, you can use other libraries such as statsmodels or pyomo for linear regression, but scikit-learn library is one of the most popular and widely used ones.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 51, 'completion_tokens': 419, 'total_tokens': 470}}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caca9e6f-1e23-440c-8df8-1b4a9fe8a647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SYSTEM: You are a helpful assistant and your task is to help the users with their questions in the prompt. answer in as much detail as possible\n",
      "\n",
      "USER: Write a code for linear regression\n",
      "\n",
      "ASSISTANT: \n",
      "Of course! Linear regression is a common statistical model used to predict a continuous outcome variable based on one or more predictor variables. Here's an example of how you could implement linear regression in Python using scikit-learn library:\n",
      "```\n",
      "from sklearn.linear_model import LinearRegression\n",
      "import numpy as np\n",
      "\n",
      "# Generate some sample data\n",
      "X = np.random.normal(0, 1, size=(100, 5)) # X features\n",
      "y = np.random.normal(0, 1, size=100) # y outcome variable\n",
      "\n",
      "# Create a Linear Regression object and fit the model\n",
      "lr_model = LinearRegression()\n",
      "X_train = X[:80] # train set\n",
      "y_train = y[:80] # train labels\n",
      "lr_model.fit(X_train, y_train)\n",
      "\n",
      "# Predict on test set\n",
      "X_test = X[80:] # test set\n",
      "preds = lr_model.predict(X_test)\n",
      "\n",
      "# Evaluate the model\n",
      "print(\"Coefficients:\", lr_model.coef_)\n",
      "print(\"Standard error:\", lr_model.score(X_train, y_train))\n",
      "print(\"R-squared value:\", lr_model.rsquared_)\n",
      "```\n",
      "This code generates some sample data, creates a linear regression object and fits the model to the training data using `fit()` method. Then it uses the `predict()` method to make predictions on the test set. Finally, it evaluates the model's performance by printing the coefficients, standard error and R-squared value.\n",
      "\n",
      "Please note that this is just an example code and you may need to modify it according to your specific needs and data. Also, you can use other libraries such as statsmodels or pyomo for linear regression, but scikit-learn library is one of the most popular and widely used ones.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544ee28-d466-43e5-9951-e6cc5bc8d9b5",
   "metadata": {},
   "source": [
    "### To deallocate the GPU cores we allocated to the model, we will delete the model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b19a085-db6b-4372-b57b-abd608b85b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_metal_free: deallocating\n"
     ]
    }
   ],
   "source": [
    "del lcpp_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0e3b1af-2f02-41de-bea3-35e94af330ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa423b-d691-49fa-85d5-711e8811d8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
